### self-supervise learning

- self-supervise learning
- bert-masking input
  - input
    - input sequence 
    - randomly masking some tokens
  - output  word which was masked
  - model
    - transformer encoder
    - liner
    - softmax
  - loss minimize cross entropy
- bert-next sentence prediction
  - input: sentence1 and sentence2
  - output: yes or no
- downsteam tasks

  - case1: sentiment analysis
    - model
      - bert: pre-trained
      - liner: random initialization

  - case2 pos tagging
  - case3 natural language inferencee
  - case4 extraction-based question answering
- T5-Comparison
- word embedding CBOW
- Multi-lingual BERT
- GPT
  - predict next token 

- Auto-ENCONDER

  - NN encoder

  - vector

  - NN decoder

    

- De-noise Encoder
- Feature disentangle
- discrete representation